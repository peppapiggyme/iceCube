{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IceCube.Essential import *\n",
    "from IceCube.Model import *\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BoostedDecisionTree(X, y, max_depth=2, n_estimators=400, learning_rate=0.5):\n",
    "    dt = DecisionTreeClassifier(max_depth=max_depth)\n",
    "    clf = AdaBoostClassifier(base_estimator=dt, \n",
    "        n_estimators=n_estimators, learning_rate=learning_rate, random_state=SEED)\n",
    "\n",
    "    # Train classifier on training set\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    # Test classifier on testing set\n",
    "    score = clf.decision_function(X)\n",
    "    y_hat = clf.predict(X)\n",
    "    \n",
    "    accuracy = accuracy_score(y, y_hat)\n",
    "    LOGGER.info(f\"Train accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    return y_hat, score, clf\n",
    "\n",
    "\n",
    "def draw_hist(x, density=True, nbins=30):\n",
    "    gnn_better = x[error < errorx]\n",
    "    fit_better = x[error > errorx]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.hist(gnn_better, bins=nbins, color='blue', label='GNN', histtype='step', density=density)\n",
    "    plt.hist(fit_better, bins=nbins, color='orange', label='Fit', histtype='step', density=density)\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHES_TEST = list(range(11, 21))\n",
    "# BATCHES_TEST = [1]\n",
    "\n",
    "# ground truth\n",
    "true_df = get_target_angles(BATCHES_TEST)\n",
    "true_df = angles2vector(true_df)\n",
    "print(true_df.head(5))\n",
    "n = true_df[[\"nx\",\"ny\",\"nz\"]].to_numpy()\n",
    "\n",
    "# reconstructed directions\n",
    "reco_df = get_reco_angles(BATCHES_TEST)\n",
    "print(reco_df.head(5))\n",
    "n_hat = reco_df[[\"x\", \"y\", \"z\"]].to_numpy()\n",
    "\n",
    "e = reco_df[[\"ex\", \"ey\", \"ez\"]].to_numpy()\n",
    "xe = np.sum(n_hat * e, axis=1)\n",
    "print(xe.shape)\n",
    "proj = n_hat - xe[:, np.newaxis] * e\n",
    "proj /= (np.linalg.norm(proj, axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "error, az_error, ze_error = angle_errors(n, n_hat)\n",
    "print(f\"error, az_error, ze_error = {error.mean()}, {az_error.mean()}, {ze_error.mean()}\")\n",
    "\n",
    "errorx, az_errorx, ze_errorx = angle_errors(n, proj)\n",
    "print(f\"error, az_error, ze_error = {errorx.mean()}, {az_errorx.mean()}, {ze_errorx.mean()}\")\n",
    "\n",
    "idx = error > errorx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot errors\n",
    "plt.figure()\n",
    "plt.hist(error, bins=30, color='blue', label='GNN', histtype='step', density=False)\n",
    "plt.hist(error[error < errorx], bins=30, color='black', label='GNN better', histtype='step', density=False)\n",
    "plt.hist(errorx, bins=30, color='orange', label='Fit', histtype='step', density=False)\n",
    "plt.hist(errorx[error > errorx], bins=30, color='red', label='Fit better', histtype='step', density=False)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here fit_error can be considered as the goodness of fit\n",
    "# TODO try to add also the statistical uncertainty of the fit\n",
    "# i.e. sigma_coefficients\n",
    "Nbins = 100\n",
    "draw_hist(np.log10(np.sqrt(reco_df[\"fit_error\"])/reco_df[\"hits\"] + 1e-6), nbins=Nbins)\n",
    "draw_hist(np.sin(reco_df[\"zenith\"]) ** 2, nbins=Nbins)\n",
    "draw_hist(np.clip(reco_df[\"hits\"], 0, 1000), nbins=Nbins)\n",
    "draw_hist(np.log10(reco_df[\"sumc\"] + 1e-6), nbins=Nbins)\n",
    "draw_hist(np.log10(reco_df[\"dt\"] + 1e-3), nbins=Nbins)\n",
    "draw_hist(reco_df[\"unique_x\"], nbins=Nbins)\n",
    "draw_hist(reco_df[\"unique_y\"], nbins=Nbins)\n",
    "draw_hist(reco_df[\"unique_z\"], nbins=Nbins)\n",
    "draw_hist(np.arccos(xe), nbins=Nbins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reco_df inputs\n",
    "reco = reco_df[[\"fit_error\", \"sumc\", \"hits\", \"zenith\", \"ez\", \"dt\", \"unique_x\", \"unique_z\"]].to_numpy()\n",
    "reco[:, 0] = np.log10(reco[:, 0] / reco[:, 2] + 1e-6)\n",
    "reco[:, 1] = np.log10(reco[:, 1] + 1e-6)\n",
    "reco[:, 3] = np.sin(reco[:, 3]) ** 2\n",
    "reco[:, 5] = np.log10(reco[:, 5] + 1e-3)\n",
    "xe = np.arccos(xe)\n",
    "\n",
    "# load the model and predict\n",
    "LOGGER.info(\"Loading BDT model...\")\n",
    "clf = pickle.load(open(os.path.join(MODEL_PATH, 'BDT_clf.DeepHighLR.sklearn'), 'rb'))\n",
    "LOGGER.info(\"Predicting...\")\n",
    "X = np.concatenate([reco, np.abs(xe[:, np.newaxis])], axis=1)\n",
    "y_hat = clf.predict(X)\n",
    "score = clf.decision_function(X)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(idx, y_hat)\n",
    "LOGGER.info(f\"Test accuracy: {accuracy * 100:.2f}%\")\n",
    "error[y_hat] = errorx[y_hat]\n",
    "LOGGER.info(f\"error -> {error.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error, az_error, ze_error = angle_errors(n, n_hat)\n",
    "LOGGER.info(f\"error, az_error, ze_error = {error.mean()}, {az_error.mean()}, {ze_error.mean()}\")\n",
    "\n",
    "errorx, az_errorx, ze_errorx = angle_errors(n, proj)\n",
    "LOGGER.info(f\"error, az_error, ze_error = {errorx.mean()}, {az_errorx.mean()}, {ze_errorx.mean()}\")\n",
    "\n",
    "criteria = score > -0.00001\n",
    "error[criteria] = errorx[criteria]\n",
    "LOGGER.info(f\"error -> {error.mean()}\")\n",
    "\n",
    "draw_hist(np.clip(score, -0.01, 0), density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2f394aca7ca06fed1e6064aef884364492d7cdda3614a461e02e6407fc40ba69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

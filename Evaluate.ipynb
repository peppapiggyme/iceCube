{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IceCube.Essential import *\n",
    "from IceCube.Model import *\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BoostedDecisionTree(X, y, max_depth=2, n_estimators=400, learning_rate=0.5):\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED)\n",
    "\n",
    "    dt = DecisionTreeClassifier(max_depth=max_depth)\n",
    "    clf = AdaBoostClassifier(base_estimator=dt, \n",
    "        n_estimators=n_estimators, learning_rate=learning_rate, random_state=SEED)\n",
    "\n",
    "    # Train classifier on training set\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Test classifier on testing set\n",
    "    score = clf.decision_function(X)\n",
    "    y_pred = clf.predict(X)\n",
    "\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    print(\"Train Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    print(\"Test  Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "    return y_pred, score, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth\n",
    "true_df = get_target_angles([2])\n",
    "true_df = angles2vector(true_df)\n",
    "print(true_df.head(5))\n",
    "n = true_df[[\"nx\",\"ny\",\"nz\"]].to_numpy()\n",
    "\n",
    "# reconstructed directions\n",
    "reco_df = pd.read_parquet(\"/root/autodl-tmp/kaggle/working/prediction/pred_2.parquet\")\n",
    "reco_df[\"azimuth\"] = np.remainder(reco_df[\"azimuth\"], 2 * np.pi)\n",
    "print(reco_df.head(5))\n",
    "n_hat = reco_df[[\"x\", \"y\", \"z\"]].to_numpy()\n",
    "\n",
    "e = reco_df[[\"ex\", \"ey\", \"ez\"]].to_numpy()\n",
    "xe = np.sum(n_hat * e, axis=1)\n",
    "print(xe.shape)\n",
    "proj = n_hat - xe[:, np.newaxis] * e\n",
    "proj /= (np.linalg.norm(proj, axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "error, az_error, ze_error = angle_errors(n, n_hat)\n",
    "print(f\"error, az_error, ze_error = {error.mean()}, {az_error.mean()}, {ze_error.mean()}\")\n",
    "\n",
    "errorx, az_errorx, ze_errorx = angle_errors(n, proj)\n",
    "print(f\"error, az_error, ze_error = {errorx.mean()}, {az_errorx.mean()}, {ze_errorx.mean()}\")\n",
    "\n",
    "idx = error > errorx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot errors\n",
    "plt.figure()\n",
    "plt.hist(error, bins=30, color='blue', label='GNN', histtype='step', density=False)\n",
    "plt.hist(error[error < errorx], bins=30, color='black', label='GNN better', histtype='step', density=False)\n",
    "plt.hist(errorx, bins=30, color='orange', label='Fit', histtype='step', density=False)\n",
    "plt.hist(errorx[error > errorx], bins=30, color='red', label='Fit better', histtype='step', density=False)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_hist(x, density=True):\n",
    "    gnn_better = x[error < errorx]\n",
    "    fit_better = x[error > errorx]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.hist(gnn_better, bins=30, color='blue', label='GNN', histtype='step', density=density)\n",
    "    plt.hist(fit_better, bins=30, color='orange', label='Fit', histtype='step', density=density)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_hist(np.clip(reco_df[\"fit_error\"], 0, 1000))\n",
    "draw_hist(np.clip(reco_df[\"good_hits\"], 0, 1000))\n",
    "draw_hist(np.clip(reco_df[\"azimuth\"], 0, 2 * np.pi))\n",
    "draw_hist(np.clip(reco_df[\"zenith\"], 0, 2 * np.pi))\n",
    "draw_hist(reco_df[\"ez\"])\n",
    "draw_hist(xe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control\n",
    "TRAIN = True\n",
    "\n",
    "# inputs\n",
    "X = np.concatenate([\n",
    "    reco_df[[\"fit_error\", \"good_hits\", \"zenith\", \"ez\"]].to_numpy(), \n",
    "    xe[:, np.newaxis]], axis=1)\n",
    "\n",
    "if TRAIN:\n",
    "    # train the model\n",
    "    y_pred, score, clf = BoostedDecisionTree(X, idx, max_depth=3, n_estimators=800, learning_rate=0.8)\n",
    "    # save the model\n",
    "    pickle.dump(clf, open(os.path.join(MODEL_PATH, 'BDT_clf.sklearn'), 'wb'))\n",
    "else:\n",
    "    # load the model and predict\n",
    "    clf = pickle.load(open(os.path.join(MODEL_PATH, 'BDT_clf.sklearn'), 'rb'))\n",
    "    y_pred = clf.predict(X)\n",
    "    score  = clf.decision_function(X)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(idx, y_pred)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "error[y_pred] = errorx[y_pred]\n",
    "print(f\"error -> {error.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_hist(np.clip(score, -0.005, 0), density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error, az_error, ze_error = angle_errors(n, n_hat)\n",
    "print(f\"error, az_error, ze_error = {error.mean()}, {az_error.mean()}, {ze_error.mean()}\")\n",
    "\n",
    "errorx, az_errorx, ze_errorx = angle_errors(n, proj)\n",
    "print(f\"error, az_error, ze_error = {errorx.mean()}, {az_errorx.mean()}, {ze_errorx.mean()}\")\n",
    "\n",
    "criteria = score > -0.0002\n",
    "error[criteria] = errorx[criteria]\n",
    "print(f\"error -> {error.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(y_pred), len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f394aca7ca06fed1e6064aef884364492d7cdda3614a461e02e6407fc40ba69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
